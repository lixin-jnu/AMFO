{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "#===读取数据集===\n",
    "task = pd.read_pickle(r\"outData/task.pkl\")\n",
    "func = pd.read_pickle(r\"outData/func.pkl\")\n",
    "with open(r\"outData/graph.pkl\", \"rb\") as file:\n",
    "    graph = pickle.load(file)\n",
    "with open(r\"outData/user.pkl\", \"rb\") as file:\n",
    "    user = pickle.load(file)\n",
    "with open(r\"outData/node.pkl\", \"rb\") as file:\n",
    "    node = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##################################\n",
    "#----------各种工具类-----------\n",
    "##################################\n",
    "'''\n",
    "\n",
    "\n",
    "def auto_str(cls):\n",
    "\n",
    "    def __str__(self):\n",
    "        return '%s(%s)' % (type(self).__name__, ', '.join(\n",
    "            '%s=%s' % item for item in vars(self).items()))\n",
    "\n",
    "    cls.__str__ = __str__\n",
    "    return cls\n",
    "\n",
    "\n",
    "#1.任务类\n",
    "@auto_str\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, taskId, arvTime, execTime, softDdl, dataVol, cpuCore,\n",
    "                 instNum, funcId, serviceId):\n",
    "        self.taskId = taskId  #任务Id\n",
    "        self.arvTime = arvTime  #到达时间\n",
    "        self.execTime = execTime  #执行时间\n",
    "        self.softDdl = softDdl  #软截止期\n",
    "        self.dataVol = dataVol  #数据量\n",
    "        self.cpuCore = cpuCore  #Cpu核心数\n",
    "        self.instNum = instNum  #实例个数\n",
    "        self.funcId = funcId  #函数Id\n",
    "        self.serviceId = serviceId  #服务商Id\n",
    "\n",
    "\n",
    "#2.边缘节点类\n",
    "@auto_str\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, nodeId, serviceId, cpuCore, cacheCapacity, funcSet,\n",
    "                 bandwidth, recv_queue, wait_queue, exec_queue, tran_queue):\n",
    "        self.nodeId = nodeId  #节点Id\n",
    "        self.serviceId = serviceId  #服务商Id\n",
    "        self.cpuCore = cpuCore  #Cpu核心数\n",
    "        self.cacheCapacity = cacheCapacity  #缓存容量\n",
    "        self.funcSet = funcSet  #函数集合\n",
    "        self.bandwidth = bandwidth  #固定带宽\n",
    "        self.recv_queue = recv_queue  #接收队列:接收用户传输过来的任务\n",
    "        self.wait_queue = wait_queue  #等待队列\n",
    "        self.exec_queue = exec_queue  #执行队列\n",
    "        self.tran_queue = tran_queue  #传输队列:接收其它边缘节点传输过来的任务+冷启动完成的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##################################\n",
    "#----------各种工具函数-----------\n",
    "##################################\n",
    "'''\n",
    "\n",
    "\n",
    "#1.从func中按比例随机生成本次实验的函数集\n",
    "def getFuncSet(func_num):\n",
    "    net = getFuncSetByType(\".net\", func_num)\n",
    "    golang = getFuncSetByType(\"golang\", func_num)\n",
    "    python = getFuncSetByType(\"python\", func_num)\n",
    "    nodejs = getFuncSetByType(\"node.js\", func_num)\n",
    "    java = getFuncSetByType(\"java\", func_num)\n",
    "    php = getFuncSetByType(\"php\", func_num)\n",
    "    res = np.vstack((net, golang, python, nodejs, java, php))\n",
    "    return np.delete(res, np.s_[2:2 + len(res) - func_num], axis=0)\n",
    "\n",
    "\n",
    "def getFuncSetByType(runc_type, func_num):\n",
    "    n = len(func)\n",
    "    subFunc = func[func[\"runc_type\"] == runc_type]\n",
    "    m = len(subFunc)\n",
    "    num = int(np.round(func_num * (m / n)))\n",
    "    num = num if num >= 1 else 1\n",
    "    #print(runc_type, num)\n",
    "    return subFunc.sample(n=num, replace=False).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['.net', 1.0, 512.0],\n",
       "       ['golang', 2.0, 3072.0],\n",
       "       ['python', 1.0, 512.0],\n",
       "       ['python', 1.0, 128.0],\n",
       "       ['python', 4.0, 256.0],\n",
       "       ['python', 4.0, 512.0],\n",
       "       ['python', 3.0, 128.0],\n",
       "       ['python', 3.0, 128.0],\n",
       "       ['python', 9.0, 512.0],\n",
       "       ['python', 1.0, 128.0],\n",
       "       ['python', 4.0, 512.0],\n",
       "       ['node.js', 1.0, 1024.0],\n",
       "       ['node.js', 1.0, 512.0],\n",
       "       ['node.js', 1.0, 1024.0],\n",
       "       ['node.js', 10.0, 128.0],\n",
       "       ['node.js', 1.0, 128.0],\n",
       "       ['node.js', 11.0, 512.0],\n",
       "       ['java', 20.0, 512.0],\n",
       "       ['java', 8.0, 2048.0],\n",
       "       ['php', 1.0, 2048.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===初始化超参数===\n",
    "n = 125\n",
    "lambda_rate = 2\n",
    "cost_diff = 1.1  #不同服务提供商之间的传输代价\n",
    "func_num = 20  #函数集中的函数个数\n",
    "func_set = getFuncSet(func_num)\n",
    "cpu_core = 10.0  #暂时假设相同\n",
    "cache_capacity = 128 * 1024.0  #暂时假设相同\n",
    "bandwidth_sub_1 = 1000.0\n",
    "bandwidth_sub_6 = 2000.0\n",
    "bandwidth_mmWave_24 = 4000.0\n",
    "func_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===初始化每个基站的CPU核数|缓存容量|函数集合|网络带宽===\n",
    "sub_1 = np.array(\n",
    "    [30, 89, 52, 57, 93, 53, 1, 56, 12, 116, 38, 50, 86, 76, 84, 28, 22, 98])\n",
    "sub_6 = np.array([\n",
    "    103, 54, 108, 45, 95, 36, 58, 14, 6, 11, 0, 96, 88, 25, 104, 113, 80, 81,\n",
    "    94, 7, 31, 92, 115, 39, 21, 72, 4, 9, 105, 85, 37, 63, 107, 17, 79, 26\n",
    "])\n",
    "mmWave_24 = np.array([\n",
    "    32, 55, 124, 118, 101, 3, 106, 97, 66, 19, 68, 13, 122, 70, 23, 59, 15, 47,\n",
    "    10, 87, 102, 65, 29, 2, 73, 5, 75, 114, 117, 77, 33, 35, 60, 8, 46, 111,\n",
    "    112, 71, 43, 61, 27, 51, 69, 121, 90, 16, 41, 64, 67, 34, 99, 120, 123, 62,\n",
    "    100, 74, 109, 42, 119, 48, 78, 24, 83, 110, 20, 44, 91, 40, 82, 18, 49\n",
    "])\n",
    "node_list = []\n",
    "for i in np.arange(n):\n",
    "    if i in sub_1:\n",
    "        node_list.append(\n",
    "            Node(nodeId=i,\n",
    "                 serviceId=1,\n",
    "                 cpuCore=cpu_core,\n",
    "                 cacheCapacity=cache_capacity,\n",
    "                 funcSet={},\n",
    "                 bandwidth=bandwidth_sub_1,\n",
    "                 recv_queue=[],\n",
    "                 wait_queue=[],\n",
    "                 exec_queue=[],\n",
    "                 tran_queue=[]))\n",
    "    elif i in sub_6:\n",
    "        node_list.append(\n",
    "            Node(nodeId=i,\n",
    "                 serviceId=6,\n",
    "                 cpuCore=cpu_core,\n",
    "                 cacheCapacity=cache_capacity,\n",
    "                 funcSet={},\n",
    "                 bandwidth=bandwidth_sub_6,\n",
    "                 recv_queue=[],\n",
    "                 wait_queue=[],\n",
    "                 exec_queue=[],\n",
    "                 tran_queue=[]), )\n",
    "    else:  # i in mmWave_24\n",
    "        node_list.append(\n",
    "            Node(nodeId=i,\n",
    "                 serviceId=24,\n",
    "                 cpuCore=cpu_core,\n",
    "                 cacheCapacity=cache_capacity,\n",
    "                 funcSet={},\n",
    "                 bandwidth=bandwidth_mmWave_24,\n",
    "                 recv_queue=[],\n",
    "                 wait_queue=[],\n",
    "                 exec_queue=[],\n",
    "                 tran_queue=[]))\n",
    "node_list = np.array(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===初始化新的Sub_1|Sub_6|mmWave_24|Cross_net基站拓扑图===\n",
    "G_sub_1 = graph[\"sub-1\"]\n",
    "G_sub_6 = graph[\"sub-6\"]\n",
    "G_mmWave_24 = graph[\"mmWave-24\"]\n",
    "G_cross_net = graph[\"cross-net\"]\n",
    "\n",
    "for u, v, _ in G_sub_1.edges(data=True):\n",
    "    G_sub_1[u][v][\"weight\"] = 1.0 / bandwidth_sub_1\n",
    "\n",
    "for u, v, _ in G_sub_6.edges(data=True):\n",
    "    G_sub_6[u][v][\"weight\"] = 1.0 / bandwidth_sub_6\n",
    "\n",
    "for u, v, _ in G_mmWave_24.edges(data=True):\n",
    "    G_mmWave_24[u][v][\"weight\"] = 1.0 / bandwidth_mmWave_24\n",
    "\n",
    "for u, v, _ in G_cross_net.edges(data=True):\n",
    "    if u in sub_1:\n",
    "        bandwidth = bandwidth_sub_1\n",
    "    elif u in sub_6:\n",
    "        bandwidth = bandwidth_sub_6\n",
    "    else:\n",
    "        bandwidth = bandwidth_mmWave_24\n",
    "    if (u in sub_1 and v in sub_1) or (u in sub_6\n",
    "                                       and v in sub_6) or (u in mmWave_24\n",
    "                                                           and v in mmWave_24):\n",
    "        G_cross_net[u][v][\"weight\"] = 1.0 / bandwidth\n",
    "    else:\n",
    "        G_cross_net[u][v][\"weight\"] = cost_diff / bandwidth\n",
    "\n",
    "G = {}\n",
    "G[1] = G_sub_1\n",
    "G[6] = G_sub_6\n",
    "G[24] = G_mmWave_24\n",
    "G[\"cross-net\"] = G_cross_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##################################\n",
    "#----------节点选择策略-----------#\n",
    "##################################\n",
    "'''\n",
    "\n",
    "\n",
    "#min_dis_own:选择距离最近的本服务提供商的基站\n",
    "def NS_min_dis_own(userId, funcId=-1):\n",
    "    serviceId = 1 if userId % 3 == 1 else (6 if userId % 3 == 2 else 24)\n",
    "    sortedNdLst = sorted(user[userId], key=lambda x: x[2])\n",
    "    for nd in sortedNdLst:\n",
    "        if nd[1] == serviceId:\n",
    "            return nd[0]\n",
    "\n",
    "\n",
    "#min_dis_all:选择距离最近的基站\n",
    "def NS_min_dis_all(userId, funcId=-1):\n",
    "    return min(user[userId], key=lambda x: x[2])[0]\n",
    "\n",
    "\n",
    "#min_user:选择覆盖用户数最少的基站\n",
    "def NS_min_user(userId, funcId=-1):\n",
    "    return min(user[userId], key=lambda x: node[x[0]][0])[0]\n",
    "\n",
    "\n",
    "#max_node:选择邻居基站数最多的基站\n",
    "def NS_max_node(userId, funcId=-1):\n",
    "    return max(user[userId], key=lambda x: node[x[0]][1])[0]\n",
    "\n",
    "\n",
    "#max_cpu:选择负载最低（剩余CPU核心数最多）的基站\n",
    "def NS_max_cpu(userId, funcId=-1):\n",
    "    return max(user[userId], key=lambda x: node_list[x[0]].cpuCore)[0]\n",
    "\n",
    "\n",
    "#exist_func:选择距离最近的存在函数的基站\n",
    "def NS_exist_func(userId, funcId):\n",
    "    sortedNdLst = sorted(user[userId], key=lambda x: x[2])\n",
    "    for nd in sortedNdLst:\n",
    "        if funcId in node_list[nd[0]].funcSet:\n",
    "            return nd[0]\n",
    "    return sortedNdLst[0][0]\n",
    "\n",
    "\n",
    "NS = {\n",
    "    \"NS_min_dis_own\": NS_min_dis_own,\n",
    "    \"NS_min_dis_all\": NS_min_dis_all,\n",
    "    \"NS_min_user\": NS_min_user,\n",
    "    \"NS_max_node\": NS_max_node,\n",
    "    \"NS_max_cpu\": NS_max_cpu,\n",
    "    \"NS_exist_func\": NS_exist_func\n",
    "}\n",
    "\n",
    "# print(NS_min_dis_own(0))\n",
    "# print(NS_min_dis_all(0))\n",
    "# print(NS_min_user(0))\n",
    "# print(NS_max_node(0))\n",
    "# print(NS_max_cpu(0))\n",
    "# print(NS_exist_func(0, 1))\n",
    "# print(NS_exist_func(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##################################\n",
    "#----------路径选择策略-----------#\n",
    "##################################\n",
    "'''\n",
    "\n",
    "\n",
    "#min_dis:寻找可以处理任务task的距离节点nodeId最近的边缘节点\n",
    "def PS_min_dis(G, nodeId, task):\n",
    "    #按照距离边缘节点nodeId的最短路径大小正序排序\n",
    "    for tarNd, count in nx.single_source_dijkstra_path_length(G,\n",
    "                                                              nodeId).items():\n",
    "        if tarNd == nodeId:\n",
    "            continue\n",
    "        #print(tarNd, count)\n",
    "        tarNd = node_list[tarNd]\n",
    "        if (task.cpuCore <= tarNd.cpuCore) and (\n",
    "                task.instNum * func_set[task.funcId][2]\n",
    "                <= tarNd.cacheCapacity) and (task.funcId in tarNd.funcSet):\n",
    "            return tarNd.nodeId, task.dataVol * count\n",
    "    return -1, np.finfo(np.float32).max\n",
    "\n",
    "\n",
    "#max_cpu:寻找可以处理任务task的剩余Cpu核心数最多的边缘节点\n",
    "def PS_max_cpu(G, nodeId, task):\n",
    "    #按照剩余Cpu核心数倒序排序,如果相同按照距离边缘节点nodeId的最短路径大小正序排序\n",
    "    sortedNdlst = sorted(\n",
    "        G.nodes(),\n",
    "        key=lambda x: (-node_list[x].cpuCore,\n",
    "                       nx.shortest_path_length(G, nodeId, x, weight=\"weight\")))\n",
    "    for tarNd in sortedNdlst:\n",
    "        if tarNd == nodeId:\n",
    "            continue\n",
    "        tarNd = node_list[tarNd]\n",
    "        if (task.cpuCore <= tarNd.cpuCore) and (\n",
    "                task.instNum * func_set[task.funcId][2]\n",
    "                <= tarNd.cacheCapacity) and (task.funcId in tarNd.funcSet):\n",
    "            return tarNd.nodeId, task.dataVol * nx.shortest_path_length(\n",
    "                G, nodeId, tarNd.nodeId, weight=\"weight\")\n",
    "    return -1, np.finfo(np.float32).max\n",
    "\n",
    "\n",
    "#max_cache:寻找可以处理任务task的剩余缓存容量最多的边缘节点\n",
    "def PS_max_cache(G, nodeId, task):\n",
    "    #按照剩余缓存容量倒序排序,如果相同按照距离边缘节点nodeId的最短路径大小正序排序\n",
    "    sortedNdlst = sorted(\n",
    "        G.nodes(),\n",
    "        key=lambda x: (-node_list[x].cacheCapacity,\n",
    "                       nx.shortest_path_length(G, nodeId, x, weight=\"weight\")))\n",
    "    for tarNd in sortedNdlst:\n",
    "        if tarNd == nodeId:\n",
    "            continue\n",
    "        tarNd = node_list[tarNd]\n",
    "        if (task.cpuCore <= tarNd.cpuCore) and (\n",
    "                task.instNum * func_set[task.funcId][2]\n",
    "                <= tarNd.cacheCapacity) and (task.funcId in tarNd.funcSet):\n",
    "            return tarNd.nodeId, task.dataVol * nx.shortest_path_length(\n",
    "                G, nodeId, tarNd.nodeId, weight=\"weight\")\n",
    "    return -1, np.finfo(np.float32).max\n",
    "\n",
    "\n",
    "PS = {\n",
    "    \"PS_min_dis\": PS_min_dis,\n",
    "    \"PS_max_cache\": PS_max_cache,\n",
    "    \"PS_max_cpu\": PS_max_cpu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##################################\n",
    "#----------任务排序策略-----------#\n",
    "##################################\n",
    "'''\n",
    "\n",
    "\n",
    "#exec_time_asc:按照任务的执行时间升序排序\n",
    "def TS_exec_time_asc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: x.execTime)\n",
    "\n",
    "\n",
    "#exec_time_desc:按照任务的执行时间降序排序\n",
    "def TS_exec_time_desc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: -x.execTime)\n",
    "\n",
    "\n",
    "#data_vol_asc:按照任务的数据量升序排序\n",
    "def TS_data_vol_asc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: x.dataVol)\n",
    "\n",
    "\n",
    "#data_vol_desc:按照任务的数据量降序排序\n",
    "def TS_data_vol_desc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: -x.dataVol)\n",
    "\n",
    "\n",
    "#exec_time_to_data_vol_ratio_asc:按照任务的执行时间/数据量升序排序\n",
    "def TS_exec_time_to_data_vol_ratio_asc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: x.execTime / x.dataVol)\n",
    "\n",
    "\n",
    "#exec_time_to_data_vol_ratio_desc:按照任务的执行时间/数据量降序排序\n",
    "def TS_exec_time_to_data_vol_ratio_desc(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: -x.execTime / x.dataVol)\n",
    "\n",
    "\n",
    "#closest_soft_ddl:按照任务的软截止期逼近程度排序\n",
    "def TS_closest_soft_ddl(wait_queue, cur_time):\n",
    "    return sorted(wait_queue, key=lambda x: x.arvTime + x.softDdl - cur_time)\n",
    "\n",
    "\n",
    "#highest_response_ratio:按照任务的响应比降序排序\n",
    "def TS_highest_response_ratio(wait_queue, cur_time):\n",
    "    return sorted(\n",
    "        wait_queue,\n",
    "        key=lambda x: -(x.execTime + cur_time - x.arvTime) / x.execTime)\n",
    "\n",
    "\n",
    "TS = {\n",
    "    \"TS_exec_time_asc\": TS_exec_time_asc,\n",
    "    \"TS_exec_time_desc\": TS_exec_time_desc,\n",
    "    \"TS_data_vol_asc\": TS_data_vol_asc,\n",
    "    \"TS_data_vol_desc\": TS_data_vol_desc,\n",
    "    \"TS_exec_time_to_data_vol_ratio_asc\": TS_exec_time_to_data_vol_ratio_asc,\n",
    "    \"TS_exec_time_to_data_vol_ratio_desc\": TS_exec_time_to_data_vol_ratio_desc,\n",
    "    \"TS_closest_soft_ddl\": TS_closest_soft_ddl,\n",
    "    \"TS_highest_response_ratio\": TS_highest_response_ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_num = 10  #len(task)  #任务总数\n",
    "task_over_num = 0  #已完成任务\n",
    "task_use_num = 0  #当前使用到数据集中的第几个任务|下次拿任务从第task_use_num个获取\n",
    "\n",
    "t = 0\n",
    "\n",
    "#指定各算法组件的策略\n",
    "node_selection_strategy = \"NS_min_dis_all\"\n",
    "path_selection_strategy = \"PS_min_dis\"\n",
    "task_sorting_strategy = \"TS_closest_soft_ddl\"\n",
    "\n",
    "#-------------------------\n",
    "#1.思考如何进行任务延迟时间的计算\n",
    "arrivalDic = {}\n",
    "delayDic = {}\n",
    "#2.以及如何判断程序结束\n",
    "#-------------------------\n",
    "\n",
    "#在每一时隙开始时进行调度\n",
    "while task_over_num < task_num:\n",
    "\n",
    "    print(\"now time slot\", t)\n",
    "\n",
    "    #边缘节点不同队列的数据格式\n",
    "    #recv_queue|tram_queue->[[task,t],...]\n",
    "    #wait_queue|exec_queue->[task,...]\n",
    "\n",
    "    #在新时隙开始时对每个边缘节点的接收队列+传输队列+执行队列中的时间都减1\n",
    "    for nd in np.arange(n):\n",
    "        curNd = node_list[nd]\n",
    "        RecvQe = curNd.recv_queue\n",
    "        TranQe = curNd.tran_queue\n",
    "        ExecQe = curNd.exec_queue\n",
    "        for i in range(len(RecvQe) - 1, -1, -1):\n",
    "            RecvQe[i][1] -= 1\n",
    "        for i in range(len(TranQe) - 1, -1, -1):\n",
    "            TranQe[i][1] -= 1\n",
    "        for i in range(len(ExecQe) - 1, -1, -1):\n",
    "            ExecQe[i].execTime -= 1\n",
    "            #不仅执行时间-1,还要恢复Cpu核心数+缓存容量+删除任务+删除函数\n",
    "            if ExecQe[i].execTime == 0:\n",
    "                curNd.funcSet[ExecQe[i].funcId] -= 1\n",
    "                if curNd.funcSet[ExecQe[i].funcId] == 0:\n",
    "                    del curNd.funcSet[ExecQe[i].funcId]\n",
    "                curNd.cpuCore += ExecQe[i].cpuCore\n",
    "                curNd.cacheCapacity += ExecQe[i].instNum * func_set[\n",
    "                    ExecQe[i].funcId][2]\n",
    "                del ExecQe[i]\n",
    "\n",
    "    #依旧存在没有到来的任务\n",
    "    if task_use_num < task_num:\n",
    "        #每个用户开始生成任务\n",
    "        for u in user:\n",
    "            if task_use_num >= task_num:\n",
    "                break\n",
    "            #该用户在t时隙生成的任务个数\n",
    "            utNum = np.random.poisson(lambda_rate)\n",
    "            print(\"user:\", u, \"->\", utNum, \"tasks\")\n",
    "            print(min(user[u], key=lambda x: x[2]))\n",
    "            for i in np.arange(utNum):\n",
    "                if task_use_num >= task_num:\n",
    "                    break\n",
    "                #构建任务对象\n",
    "                tk = Task(taskId=task_use_num,\n",
    "                          arvTime=t,\n",
    "                          execTime=task.iloc[task_use_num, 0],\n",
    "                          softDdl=task.iloc[task_use_num, 4],\n",
    "                          dataVol=task.iloc[task_use_num, 1],\n",
    "                          cpuCore=task.iloc[task_use_num, 3],\n",
    "                          instNum=task.iloc[task_use_num, 2],\n",
    "                          funcId=np.random.randint(0, func_num),\n",
    "                          serviceId=1 if u % 3 == 1 else\n",
    "                          (6 if u % 3 == 2 else 24))\n",
    "                #arrivalDic[tk.taskId] = t\n",
    "                print(\"----------\")\n",
    "                print(str(tk))\n",
    "                '''\n",
    "                #-----------------#\n",
    "                #   节点选择组件   #\n",
    "                #-----------------#\n",
    "                '''\n",
    "                selectedNode = NS[node_selection_strategy](u, tk.funcId)\n",
    "                #-----------------#\n",
    "                #    Recv_Queue   #\n",
    "                #-----------------#\n",
    "                node_list[selectedNode].recv_queue.append([\n",
    "                    tk,\n",
    "                    math.ceil(tk.dataVol /\n",
    "                              (node_list[selectedNode].bandwidth /\n",
    "                               node[selectedNode][0]))  #数据量/(基站带宽/基站覆盖用户数)\n",
    "                ])\n",
    "                print(\"select node\", selectedNode)\n",
    "                print(\"this node bandwidth\", node_list[selectedNode].bandwidth)\n",
    "                print(\"this node has\", node[selectedNode][0], \"users\")\n",
    "                print(node_list[selectedNode].recv_queue)\n",
    "                print(\"----------\")\n",
    "                task_use_num += 1\n",
    "\n",
    "    #对每个边缘节点接收到的到期任务进行卸载决策并放入到对应边缘节点的等待队列或传输队列\n",
    "    for nd in np.arange(n):\n",
    "        curNd = node_list[nd]\n",
    "        RecvQe = curNd.recv_queue\n",
    "        for i in range(len(RecvQe) - 1, -1, -1):\n",
    "            #任务tk到达边缘节点nd\n",
    "            if RecvQe[i][1] == 0:\n",
    "                tk = RecvQe[i][0]\n",
    "                del RecvQe[i]\n",
    "                '''\n",
    "                #-----------------#\n",
    "                #   卸载决策组件   #\n",
    "                #-----------------#\n",
    "                '''\n",
    "                #Local:当前边缘节点即可处理该任务(Cpu+缓存+存在函数)\n",
    "                if (tk.cpuCore <= curNd.cpuCore) and (\n",
    "                        tk.instNum * func_set[tk.funcId][2]\n",
    "                        <= curNd.cacheCapacity) and (tk.funcId\n",
    "                                                     in curNd.funcSet):\n",
    "                    #-----------------#\n",
    "                    #    Wait_Queue   #\n",
    "                    #-----------------#\n",
    "                    curNd.wait_queue.append(tk)\n",
    "                    continue\n",
    "                '''\n",
    "                #-----------------#\n",
    "                #   路径选择组件   #\n",
    "                #-----------------#\n",
    "                '''\n",
    "                #Inter-Edge:在该基站的内网寻找其它基站处理该任务\n",
    "                ieNd, ieCost = PS[path_selection_strategy](G[curNd.serviceId],\n",
    "                                                           nd, tk)\n",
    "                #Cross-Edge:在全网寻找其它基站处理该任务\n",
    "                ceNd, ceCost = PS[path_selection_strategy](G[\"cross-net\"], nd,\n",
    "                                                           tk)\n",
    "                #Cold-start:在当前边缘节点冷启动处理该任务\n",
    "                csNd, csCost = nd, func_set[tk.funcId][1]\n",
    "                #选择代价最小的处理方式\n",
    "                offload_decision = min(\n",
    "                    [[ieNd, ieCost], [ceNd, ceCost], [csNd, csCost]],\n",
    "                    key=lambda x: x[1])\n",
    "                #-----------------#\n",
    "                #    Tran_Queue   #\n",
    "                #-----------------#\n",
    "                node_list[offload_decision[0]].tran_queue.append(\n",
    "                    [tk, math.ceil(offload_decision[1])])\n",
    "\n",
    "    #将每个边缘节点卸载而来的任务+冷启动完成的任务放入执行队列\n",
    "    for nd in np.arange(n):\n",
    "        curNd = node_list[nd]\n",
    "        TranQe = curNd.tran_queue\n",
    "        for i in range(len(TranQe) - 1, -1, -1):\n",
    "            if TranQe[i][1] == 0:\n",
    "                tk = TranQe[i][0]\n",
    "                del TranQe[i]\n",
    "                #-----------------#\n",
    "                #    Wait_Queue   #\n",
    "                #-----------------#\n",
    "                curNd.wait_queue.append(tk)\n",
    "\n",
    "    #对每个边缘节点等待队列中的任务进行任务排序并依次放入执行队列\n",
    "    for nd in np.arange(n):\n",
    "        curNd = node_list[nd]\n",
    "        '''\n",
    "        #-----------------#\n",
    "        #   任务排序组件   #\n",
    "        #-----------------#\n",
    "        '''\n",
    "        curNd.wait_queue = TS[task_sorting_strategy](curNd.wait_queue, t)\n",
    "        WaitQe = curNd.wait_queue\n",
    "        for i in range(len(WaitQe) - 1, -1, -1):\n",
    "            tk = WaitQe[i]\n",
    "            if tk.cpuCore <= curNd.cpuCore and (tk.instNum *\n",
    "                                                func_set[tk.funcId][2]\n",
    "                                                <= curNd.cacheCapacity):\n",
    "                #-----------------#\n",
    "                #    Exec_Queue   #\n",
    "                #-----------------#\n",
    "                curNd.exec_queue.append(tk)\n",
    "                curNd.funcSet[tk.funcId] = curNd.funcSet.get(tk.funcId, 0) + 1\n",
    "                curNd.cpuCore -= tk.cpuCore\n",
    "                curNd.cacheCapacity -= tk.instNum * func_set[tk.funcId][2]\n",
    "                del WaitQe[i]\n",
    "\n",
    "    t += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
